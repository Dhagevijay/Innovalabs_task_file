{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ef748a",
   "metadata": {},
   "source": [
    "# 1). Email Spam Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load spam and ham email datasets (replace with your own dataset)\n",
    "spam_emails = []  # List of spam emails\n",
    "ham_emails = []   # List of non-spam (ham) emails\n",
    "# Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "all_emails = spam_emails + ham_emails\n",
    "labels = ['spam'] * len(spam_emails) + ['ham'] * len(ham_emails)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_emails, labels, test_size=0.2, random_state=42)\n",
    "# Vectorize the emails\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=stop_words)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = classifier.score(X_test_vectorized, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Test with new email\n",
    "new_email = [\"This is a spam email with a great offer!\"]\n",
    "new_email_vectorized = vectorizer.transform(new_email)\n",
    "prediction = classifier.predict(new_email_vectorized)\n",
    "print(\"Prediction:\", prediction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2). Finding total no of speaker in audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc31047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize speaker count\n",
    "speaker_count = 0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    frame = imutils.resize(frame, width=800)\n",
    "# Detect faces in the frame\n",
    "    faces = detector(frame, 0)\n",
    "\n",
    "    # Count the number of detected faces\n",
    "    speaker_count += len(faces)\n",
    "\n",
    "    # Detect objects in the frame (replace with your preferred object detection code)\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "# Iterate over detected objects\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # Filter out weak detections\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # Draw bounding box around the object\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "# Display the frame\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# Print the total number of speakers detected\n",
    "print(\"Total number of speakers:\", speaker_count)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1bbe5",
   "metadata": {},
   "source": [
    "# 3). Fetching Images From The Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb5505",
   "metadata": {},
   "outputs": [],
   "source": [
    "Import cv2   \n",
    "Image_video=cv2.videocapture(We have to give video path from where we need to extra images.)\n",
    "Currentframe=0\n",
    "While (True) :\n",
    "         Success, frame =  image_video.read()   # read the frame (image information)from the video\n",
    "         Cv2.imshow(“Output”, frame)          # show the frame from the video\n",
    "        Cv2.inwrite(‘frame’ +  str(currentframe) + ‘.jpg’, frame )  # storing the information of the frame.\n",
    "       Currentframe +=1\n",
    "\n",
    "If cv2.writkey (1) &  0xff == ord(‘q’):     # close the extraction of frame from the video after extracting all the images.\n",
    "         Break\n",
    "\n",
    "Image_video.release()\n",
    "cv2.destroyALLWindows().\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
